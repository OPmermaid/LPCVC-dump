{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "# from src import data_loader\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the 'playground' folder to the Python path\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "from utils.data_loader import get_train_data_loaders\n",
    "import wandb\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegformerTrainer:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Initialize wandb\n",
    "        wandb.init(\n",
    "            project=\"disaster-segmentation\",\n",
    "            config=config\n",
    "        )\n",
    "        \n",
    "        # Setup data loaders\n",
    "        self.train_loader, self.val_loader = get_train_data_loaders(\n",
    "            root_dir=config['data_path'],\n",
    "            validation_split=config['val_split'],\n",
    "            batch_size=config['batch_size']\n",
    "        )\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "            config['model_name'],\n",
    "            num_labels=config['num_classes'],\n",
    "            id2label={str(i): label for i, label in enumerate(config['class_names'])},\n",
    "            label2id={label: str(i) for i, label in enumerate(config['class_names'])}\n",
    "        )\n",
    "        self.model = self.model.to(self.device)\n",
    "        \n",
    "        # Setup optimizer and scheduler\n",
    "        self.optimizer = optim.AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=config['learning_rate'],\n",
    "            weight_decay=config['weight_decay']\n",
    "        )\n",
    "        \n",
    "        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "            self.optimizer,\n",
    "            T_max=config['epochs'],\n",
    "            eta_min=config['min_lr']\n",
    "        )\n",
    "        \n",
    "        # Setup loss function with class weights\n",
    "        class_weights = self._calculate_class_weights()\n",
    "        self.criterion = nn.CrossEntropyLoss(weight=class_weights.to(self.device))\n",
    "\n",
    "    def _calculate_class_weights(self):\n",
    "        \"\"\"Calculate class weights based on the class proportions from EDA\"\"\"\n",
    "        class_proportions = {\n",
    "            'background': 0.6242538624015307,\n",
    "            'avalanche': 0.013283235435971551,\n",
    "            'building_undamaged': 0.05180814333924117,\n",
    "            'building_damaged': 0.03242294281633547,\n",
    "            'cracks/fissure/subsidence': 0.0489093545134691,\n",
    "            'debris/mud//rock flow': 0.06460793595122544,\n",
    "            'fire/flare': 0.007107057487345816,\n",
    "            'flood/water/river/sea': 0.0633561099778193,\n",
    "            'ice_jam_flow': 0.01517923711913106,\n",
    "            'lava_flow': 0.004472839026679955,\n",
    "            'person': 0.000470474347778679,\n",
    "            'pyroclastic_flow': 0.014284453359336742,\n",
    "            'road/railway/bridge': 0.0537863123311819,\n",
    "            'vehicle': 0.006058041892953064\n",
    "        }\n",
    "        \n",
    "        # Convert proportions to weights (inverse frequency)\n",
    "        weights = torch.tensor([\n",
    "            1.0 / (prop + 1e-6)  # adding small epsilon to avoid division by zero\n",
    "            for prop in class_proportions.values()\n",
    "        ])\n",
    "        \n",
    "        # Normalize weights\n",
    "        weights = weights / weights.sum()\n",
    "        return weights\n",
    "\n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        pbar = tqdm(self.train_loader, desc='Training')\n",
    "        for batch_idx, (images, masks) in enumerate(pbar):\n",
    "            images = images.to(self.device)\n",
    "            masks = masks.to(self.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            outputs = self.model(pixel_values=images, labels=masks)\n",
    "            loss = outputs.loss\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "            \n",
    "            wandb.log({\n",
    "                'batch_loss': loss.item(),\n",
    "                'learning_rate': self.optimizer.param_groups[0]['lr']\n",
    "            })\n",
    "        \n",
    "        return total_loss / len(self.train_loader)\n",
    "\n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, masks in tqdm(self.val_loader, desc='Validation'):\n",
    "                images = images.to(self.device)\n",
    "                masks = masks.to(self.device)\n",
    "                \n",
    "                outputs = self.model(pixel_values=images, labels=masks)\n",
    "                loss = outputs.loss\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "        \n",
    "        return total_loss / len(self.val_loader)\n",
    "\n",
    "    def train(self):\n",
    "        best_val_loss = float('inf')\n",
    "        \n",
    "        for epoch in range(self.config['epochs']):\n",
    "            print(f\"\\nEpoch {epoch+1}/{self.config['epochs']}\")\n",
    "            \n",
    "            train_loss = self.train_epoch()\n",
    "            val_loss = self.validate()\n",
    "            \n",
    "            self.scheduler.step()\n",
    "            \n",
    "            # Log metrics\n",
    "            wandb.log({\n",
    "                'epoch': epoch,\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss\n",
    "            })\n",
    "            \n",
    "            print(f'Train Loss: {train_loss:.4f}')\n",
    "            print(f'Val Loss: {val_loss:.4f}')\n",
    "            \n",
    "            # Save best model\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                self.save_model('best_model.pth')\n",
    "            \n",
    "            # Regular checkpoint\n",
    "            if (epoch + 1) % self.config['save_every'] == 0:\n",
    "                self.save_model(f'checkpoint_epoch_{epoch+1}.pth')\n",
    "\n",
    "    def save_model(self, filename):\n",
    "        save_path = os.path.join(self.config['save_dir'], filename)\n",
    "        os.makedirs(self.config['save_dir'], exist_ok=True)\n",
    "        \n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "            'config': self.config\n",
    "        }, save_path)\n",
    "        \n",
    "        print(f'Model saved to {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    config = {\n",
    "        'data_path': 'D:/alib/LPCVC2023/data/LPCVC_Train_Updated/LPCVC_Train_Updated/LPCVC_Train_Updated',\n",
    "        'model_name': 'nvidia/mit-b0',  # or 'nvidia/mit-b1', 'nvidia/mit-b2', etc.\n",
    "        'num_classes': 14,\n",
    "        'class_names': [\n",
    "            'background', 'avalanche', 'building_undamaged', 'building_damaged',\n",
    "            'cracks/fissure/subsidence', 'debris/mud//rock flow', 'fire/flare',\n",
    "            'flood/water/river/sea', 'ice_jam_flow', 'lava_flow', 'person',\n",
    "            'pyroclastic_flow', 'road/railway/bridge', 'vehicle'\n",
    "        ],\n",
    "        'batch_size': 8,\n",
    "        'epochs': 50,\n",
    "        'learning_rate': 1e-4,\n",
    "        'min_lr': 1e-6,\n",
    "        'weight_decay': 0.01,\n",
    "        'val_split': 0.2,\n",
    "        'save_dir': 'checkpoints',\n",
    "        'save_every': 5\n",
    "    }\n",
    "    \n",
    "    trainer = SegformerTrainer(config)\n",
    "    trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
