{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\alib\\LPCVC2023\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import segmentation_models_pytorch as smp\n",
    "# from src import data_loader\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add the parent directory of the 'playground' folder to the Python path\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.insert(0, PROJECT_ROOT)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "from utils.data_loader import get_train_data_loaders\n",
    "import wandb\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegformerTrainer:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # Initialize wandb\n",
    "        wandb.init(\n",
    "            project=\"disaster-segmentation\",\n",
    "            config=config\n",
    "        )\n",
    "        \n",
    "        # Setup data loaders\n",
    "        self.train_loader, self.val_loader = get_train_data_loaders(\n",
    "            root_dir=config['data_path'],\n",
    "            validation_split=config['val_split'],\n",
    "            batch_size=config['batch_size']\n",
    "        )\n",
    "        \n",
    "        # Initialize model\n",
    "        self.model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "            config['model_name'],\n",
    "            num_labels=config['num_classes'],\n",
    "            id2label={str(i): label for i, label in enumerate(config['class_names'])},\n",
    "            label2id={label: str(i) for i, label in enumerate(config['class_names'])}\n",
    "        )\n",
    "        self.model = self.model.to(self.device)\n",
    "        \n",
    "        # Setup optimizer and scheduler\n",
    "        self.optimizer = optim.AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=config['learning_rate'],\n",
    "            weight_decay=config['weight_decay']\n",
    "        )\n",
    "        \n",
    "        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "            self.optimizer,\n",
    "            T_max=config['epochs'],\n",
    "            eta_min=config['min_lr']\n",
    "        )\n",
    "        \n",
    "        # Setup loss function with class weights\n",
    "        class_weights = self._calculate_class_weights()\n",
    "        self.criterion = nn.CrossEntropyLoss(weight=class_weights.to(self.device))\n",
    "\n",
    "    def _calculate_class_weights(self):\n",
    "        \"\"\"Calculate class weights based on the class proportions from EDA\"\"\"\n",
    "        class_proportions = {\n",
    "            'background': 0.6242538624015307,\n",
    "            'avalanche': 0.013283235435971551,\n",
    "            'building_undamaged': 0.05180814333924117,\n",
    "            'building_damaged': 0.03242294281633547,\n",
    "            'cracks/fissure/subsidence': 0.0489093545134691,\n",
    "            'debris/mud//rock flow': 0.06460793595122544,\n",
    "            'fire/flare': 0.007107057487345816,\n",
    "            'flood/water/river/sea': 0.0633561099778193,\n",
    "            'ice_jam_flow': 0.01517923711913106,\n",
    "            'lava_flow': 0.004472839026679955,\n",
    "            'person': 0.000470474347778679,\n",
    "            'pyroclastic_flow': 0.014284453359336742,\n",
    "            'road/railway/bridge': 0.0537863123311819,\n",
    "            'vehicle': 0.006058041892953064\n",
    "        }\n",
    "        \n",
    "        # Convert proportions to weights (inverse frequency)\n",
    "        weights = torch.tensor([\n",
    "            1.0 / (prop + 1e-6)  # adding small epsilon to avoid division by zero\n",
    "            for prop in class_proportions.values()\n",
    "        ])\n",
    "        \n",
    "        # Normalize weights\n",
    "        weights = weights / weights.sum()\n",
    "        return weights\n",
    "\n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        pbar = tqdm(self.train_loader, desc='Training')\n",
    "        for batch_idx, (images, masks) in enumerate(pbar):\n",
    "            images = images.to(self.device)\n",
    "            masks = masks.to(self.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            outputs = self.model(pixel_values=images, labels=masks)\n",
    "            loss = outputs.loss\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "            \n",
    "            wandb.log({\n",
    "                'batch_loss': loss.item(),\n",
    "                'learning_rate': self.optimizer.param_groups[0]['lr']\n",
    "            })\n",
    "        \n",
    "        return total_loss / len(self.train_loader)\n",
    "\n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, masks in tqdm(self.val_loader, desc='Validation'):\n",
    "                images = images.to(self.device)\n",
    "                masks = masks.to(self.device)\n",
    "                \n",
    "                outputs = self.model(pixel_values=images, labels=masks)\n",
    "                loss = outputs.loss\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "        \n",
    "        return total_loss / len(self.val_loader)\n",
    "\n",
    "    def train(self):\n",
    "        best_val_loss = float('inf')\n",
    "        \n",
    "        for epoch in range(self.config['epochs']):\n",
    "            print(f\"\\nEpoch {epoch+1}/{self.config['epochs']}\")\n",
    "            \n",
    "            train_loss = self.train_epoch()\n",
    "            val_loss = self.validate()\n",
    "            \n",
    "            self.scheduler.step()\n",
    "            \n",
    "            # Log metrics\n",
    "            wandb.log({\n",
    "                'epoch': epoch,\n",
    "                'train_loss': train_loss,\n",
    "                'val_loss': val_loss\n",
    "            })\n",
    "            \n",
    "            print(f'Train Loss: {train_loss:.4f}')\n",
    "            print(f'Val Loss: {val_loss:.4f}')\n",
    "            \n",
    "            # Save best model\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                self.save_model('best_model.pth')\n",
    "            \n",
    "            # Regular checkpoint\n",
    "            if (epoch + 1) % self.config['save_every'] == 0:\n",
    "                self.save_model(f'checkpoint_epoch_{epoch+1}.pth')\n",
    "\n",
    "    def save_model(self, filename):\n",
    "        save_path = os.path.join(self.config['save_dir'], filename)\n",
    "        os.makedirs(self.config['save_dir'], exist_ok=True)\n",
    "        \n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "            'config': self.config\n",
    "        }, save_path)\n",
    "        \n",
    "        print(f'Model saved to {save_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    config = {\n",
    "        'data_path': 'D:/alib/LPCVC2023/data/LPCVC_Train_Updated/LPCVC_Train_Updated/LPCVC_Train_Updated',\n",
    "        'model_name': 'nvidia/mit-b0',  # or 'nvidia/mit-b1', 'nvidia/mit-b2', etc.\n",
    "        'num_classes': 14,\n",
    "        'class_names': [\n",
    "            'background', 'avalanche', 'building_undamaged', 'building_damaged',\n",
    "            'cracks/fissure/subsidence', 'debris/mud//rock flow', 'fire/flare',\n",
    "            'flood/water/river/sea', 'ice_jam_flow', 'lava_flow', 'person',\n",
    "            'pyroclastic_flow', 'road/railway/bridge', 'vehicle'\n",
    "        ],\n",
    "        'batch_size': 8,\n",
    "        'epochs': 50,\n",
    "        'learning_rate': 1e-4,\n",
    "        'min_lr': 1e-6,\n",
    "        'weight_decay': 0.01,\n",
    "        'val_split': 0.2,\n",
    "        'save_dir': 'checkpoints',\n",
    "        'save_every': 5\n",
    "    }\n",
    "    \n",
    "    trainer = SegformerTrainer(config)\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegformerTrainer:\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        # Setup data loaders\n",
    "        self.train_loader, self.val_loader = self._setup_data_loaders(\n",
    "            img_path=config['img_path'],\n",
    "            gt_path=config['gt_path'],\n",
    "            validation_split=config['val_split'],\n",
    "            batch_size=config['batch_size']\n",
    "        )\n",
    "\n",
    "        # Initialize model\n",
    "        self.model = SegformerForSemanticSegmentation.from_pretrained(\n",
    "            config['model_name'],\n",
    "            num_labels=config['num_classes'],\n",
    "            id2label={str(i): label for i, label in enumerate(config['class_names'])},\n",
    "            label2id={label: str(i) for i, label in enumerate(config['class_names'])}\n",
    "        )\n",
    "        self.model = self.model.to(self.device)\n",
    "\n",
    "        # Setup optimizer and scheduler\n",
    "        self.optimizer = optim.AdamW(\n",
    "            self.model.parameters(),\n",
    "            lr=config['learning_rate'],\n",
    "            weight_decay=config['weight_decay']\n",
    "        )\n",
    "\n",
    "        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
    "            self.optimizer,\n",
    "            T_max=config['epochs'],\n",
    "            eta_min=config['min_lr']\n",
    "        )\n",
    "\n",
    "        # Setup loss function with class weights\n",
    "        class_weights = self._calculate_class_weights()\n",
    "        self.criterion = nn.CrossEntropyLoss(weight=class_weights.to(self.device))\n",
    "\n",
    "    def _setup_data_loaders(self, img_path, gt_path, validation_split, batch_size):\n",
    "        \"\"\"\n",
    "        Helper function to set up data loaders.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(img_path) or not os.path.exists(gt_path):\n",
    "            raise FileNotFoundError(f\"Paths {img_path} or {gt_path} do not exist.\")\n",
    "\n",
    "        return get_train_data_loaders(\n",
    "            img_dir=img_path,\n",
    "            gt_dir=gt_path,\n",
    "            validation_split=validation_split,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "\n",
    "    def _calculate_class_weights(self):\n",
    "        \"\"\"\n",
    "        Helper function to calculate class weights for the loss function.\n",
    "        Modify this function if you have a specific way to compute class weights.\n",
    "        \"\"\"\n",
    "        # Example: Uniform weights (1 for each class).\n",
    "        num_classes = self.config['num_classes']\n",
    "        return torch.ones(num_classes)\n",
    "\n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        pbar = tqdm(self.train_loader, desc='Training')\n",
    "        for batch_idx, (images, masks) in enumerate(pbar):\n",
    "            images = images.to(self.device)\n",
    "            masks = masks.to(self.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            outputs = self.model(pixel_values=images, labels=masks)\n",
    "            loss = outputs.loss\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        return total_loss / len(self.train_loader)\n",
    "\n",
    "    def validate(self):\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, masks in tqdm(self.val_loader, desc='Validation'):\n",
    "                images = images.to(self.device)\n",
    "                masks = masks.to(self.device)\n",
    "                \n",
    "                outputs = self.model(pixel_values=images, labels=masks)\n",
    "                loss = outputs.loss\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "        \n",
    "        return total_loss / len(self.val_loader)\n",
    "\n",
    "    def train(self):\n",
    "        best_val_loss = float('inf')\n",
    "        \n",
    "        for epoch in range(self.config['epochs']):\n",
    "            print(f\"\\nEpoch {epoch+1}/{self.config['epochs']}\")\n",
    "            \n",
    "            train_loss = self.train_epoch()\n",
    "            val_loss = self.validate()\n",
    "            \n",
    "            self.scheduler.step()\n",
    "            \n",
    "            print(f'Train Loss: {train_loss:.4f}')\n",
    "            print(f'Val Loss: {val_loss:.4f}')\n",
    "            \n",
    "            # Save best model\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                self.save_model('best_model.pth')\n",
    "            \n",
    "            # Regular checkpoint\n",
    "            if (epoch + 1) % self.config['save_every'] == 0:\n",
    "                self.save_model(f'checkpoint_epoch_{epoch+1}.pth')\n",
    "\n",
    "    def save_model(self, filename):\n",
    "        save_path = os.path.join(self.config['save_dir'], filename)\n",
    "        os.makedirs(self.config['save_dir'], exist_ok=True)\n",
    "        \n",
    "        torch.save({\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
    "            'config': self.config\n",
    "        }, save_path)\n",
    "        \n",
    "        print(f'Model saved to {save_path}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head.batch_norm.bias', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.batch_norm.running_mean', 'decode_head.batch_norm.running_var', 'decode_head.batch_norm.weight', 'decode_head.classifier.bias', 'decode_head.classifier.weight', 'decode_head.linear_c.0.proj.bias', 'decode_head.linear_c.0.proj.weight', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.1.proj.weight', 'decode_head.linear_c.2.proj.bias', 'decode_head.linear_c.2.proj.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.linear_c.3.proj.weight', 'decode_head.linear_fuse.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 102/102 [00:39<00:00,  2.61it/s, loss=1.3026]\n",
      "Validation: 100%|██████████| 26/26 [00:15<00:00,  1.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8558\n",
      "Val Loss: 1.2771\n",
      "Model saved to checkpoints\\best_model.pth\n",
      "\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 102/102 [00:34<00:00,  2.94it/s, loss=0.7973]\n",
      "Validation: 100%|██████████| 26/26 [00:10<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.1427\n",
      "Val Loss: 0.9483\n",
      "Model saved to checkpoints\\best_model.pth\n",
      "\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 102/102 [00:33<00:00,  3.06it/s, loss=0.7515]\n",
      "Validation: 100%|██████████| 26/26 [00:08<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.8800\n",
      "Val Loss: 0.7674\n",
      "Model saved to checkpoints\\best_model.pth\n",
      "\n",
      "Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 102/102 [00:33<00:00,  3.09it/s, loss=0.8382]\n",
      "Validation: 100%|██████████| 26/26 [00:07<00:00,  3.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7715\n",
      "Val Loss: 0.7112\n",
      "Model saved to checkpoints\\best_model.pth\n",
      "\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 102/102 [00:32<00:00,  3.10it/s, loss=0.6184]\n",
      "Validation: 100%|██████████| 26/26 [00:07<00:00,  3.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 0.7165\n",
      "Val Loss: 0.6996\n",
      "Model saved to checkpoints\\best_model.pth\n",
      "Model saved to checkpoints\\checkpoint_epoch_5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    config = {\n",
    "    'img_path': 'D:/alib/LPCVC2023/data/LPCVC_Train_Updated/LPCVC_Train_Updated/LPCVC_Train_Updated/IMG/train',\n",
    "    'gt_path': 'D:/alib/LPCVC2023/data/LPCVC_Train_Updated/LPCVC_Train_Updated/LPCVC_Train_Updated/GT_Updated/train',\n",
    "    'model_name': 'nvidia/mit-b0',\n",
    "    'num_classes': 14,\n",
    "    'class_names': [\n",
    "        'background', 'avalanche', 'building_undamaged', 'building_damaged',\n",
    "        'cracks/fissure/subsidence', 'debris/mud//rock flow', 'fire/flare',\n",
    "        'flood/water/river/sea', 'ice_jam_flow', 'lava_flow', 'person',\n",
    "        'pyroclastic_flow', 'road/railway/bridge', 'vehicle'\n",
    "    ],\n",
    "    'batch_size': 8,\n",
    "    'epochs': 5,\n",
    "    'learning_rate': 1e-4,\n",
    "    'min_lr': 1e-6,\n",
    "    'weight_decay': 0.01,\n",
    "    'val_split': 0.2,\n",
    "    'save_dir': 'checkpoints',\n",
    "    'save_every': 5\n",
    "    }\n",
    "\n",
    "    \n",
    "    trainer = SegformerTrainer(config)\n",
    "    trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
